import React, { useState, useRef } from 'react';
import { Mic, MicOff, Upload, Play, Pause, Trash2, FileAudio } from 'lucide-react';
import { useVoiceRecording } from '../hooks/useVoiceRecording';

interface VoiceInputProcessorProps {
  onTranscriptionComplete: (transcription: string, audioBlob?: Blob) => void;
  language: 'en' | 'ja';
}

interface AudioFile {
  id: string;
  name: string;
  blob: Blob;
  duration: number;
  transcription?: string;
  isProcessing: boolean;
}

const VoiceInputProcessor: React.FC<VoiceInputProcessorProps> = ({
  onTranscriptionComplete,
  language
}) => {
  const [audioFiles, setAudioFiles] = useState<AudioFile[]>([]);
  const [playingId, setPlayingId] = useState<string | null>(null);
  const { isRecording, startRecording, stopRecording, error } = useVoiceRecording();
  const fileInputRef = useRef<HTMLInputElement>(null);
  const audioRefs = useRef<{ [key: string]: HTMLAudioElement }>({});

  const texts = {
    en: {
      title: 'Voice Input Processor',
      startRecording: 'Start Recording',
      stopRecording: 'Stop Recording',
      uploadFile: 'Upload Audio File',
      processing: 'Processing...',
      transcribe: 'Transcribe',
      play: 'Play',
      pause: 'Pause',
      delete: 'Delete',
      noFiles: 'No audio files yet',
      transcriptionComplete: 'Transcription complete',
      duration: 'Duration'
    },
    ja: {
      title: '音声入力プロセッサー',
      startRecording: '録音開始',
      stopRecording: '録音停止',
      uploadFile: '音声ファイルをアップロード',
      processing: '処理中...',
      transcribe: '転写',
      play: '再生',
      pause: '一時停止',
      delete: '削除',
      noFiles: '音声ファイルがありません',
      transcriptionComplete: '転写完了',
      duration: '長さ'
    }
  };

  const t = texts[language];

  const handleRecordingComplete = async () => {
    const audioBlob = await stopRecording();
    if (audioBlob) {
      const audioFile: AudioFile = {
        id: Date.now().toString(),
        name: `Recording ${new Date().toLocaleTimeString()}`,
        blob: audioBlob,
        duration: 0, // Would be calculated from actual audio
        isProcessing: false
      };
      
      setAudioFiles(prev => [...prev, audioFile]);
      processTranscription(audioFile);
    }
  };

  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file && file.type.startsWith('audio/')) {
      const audioFile: AudioFile = {
        id: Date.now().toString(),
        name: file.name,
        blob: file,
        duration: 0,
        isProcessing: false
      };
      
      setAudioFiles(prev => [...prev, audioFile]);
      
      // Get duration
      const audio = new Audio(URL.createObjectURL(file));
      audio.onloadedmetadata = () => {
        setAudioFiles(prev => prev.map(af => 
          af.id === audioFile.id 
            ? { ...af, duration: audio.duration }
            : af
        ));
      };
    }
  };

  const processTranscription = async (audioFile: AudioFile) => {
    setAudioFiles(prev => prev.map(af => 
      af.id === audioFile.id 
        ? { ...af, isProcessing: true }
        : af
    ));

    // Simulate transcription process
    // In real implementation, you would call a speech-to-text API
    setTimeout(() => {
      const mockTranscription = language === 'en' 
        ? `Transcribed content from ${audioFile.name}: This is a sample transcription that would be generated by a speech-to-text service.`
        : `${audioFile.name}からの転写内容: これは音声認識サービスによって生成されるサンプル転写です。`;
      
      setAudioFiles(prev => prev.map(af => 
        af.id === audioFile.id 
          ? { ...af, transcription: mockTranscription, isProcessing: false }
          : af
      ));
      
      onTranscriptionComplete(mockTranscription, audioFile.blob);
    }, 2000);
  };

  const playAudio = (audioFile: AudioFile) => {
    if (playingId === audioFile.id) {
      // Pause current audio
      audioRefs.current[audioFile.id]?.pause();
      setPlayingId(null);
    } else {
      // Stop any currently playing audio
      if (playingId) {
        audioRefs.current[playingId]?.pause();
      }
      
      // Create or get audio element
      if (!audioRefs.current[audioFile.id]) {
        const audio = new Audio(URL.createObjectURL(audioFile.blob));
        audio.onended = () => setPlayingId(null);
        audioRefs.current[audioFile.id] = audio;
      }
      
      audioRefs.current[audioFile.id].play();
      setPlayingId(audioFile.id);
    }
  };

  const deleteAudioFile = (id: string) => {
    if (playingId === id) {
      audioRefs.current[id]?.pause();
      setPlayingId(null);
    }
    
    if (audioRefs.current[id]) {
      URL.revokeObjectURL(audioRefs.current[id].src);
      delete audioRefs.current[id];
    }
    
    setAudioFiles(prev => prev.filter(af => af.id !== id));
  };

  const formatDuration = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="bg-white rounded-xl border border-gray-200 p-6">
      <h3 className="text-lg font-semibold text-gray-900 mb-4">{t.title}</h3>
      
      {/* Recording Controls */}
      <div className="flex gap-3 mb-6">
        <button
          onClick={isRecording ? handleRecordingComplete : startRecording}
          className={`flex-1 flex items-center justify-center gap-2 px-4 py-3 rounded-lg font-medium transition-colors ${
            isRecording
              ? 'bg-red-500 text-white hover:bg-red-600'
              : 'bg-blue-500 text-white hover:bg-blue-600'
          }`}
        >
          {isRecording ? <MicOff className="h-5 w-5" /> : <Mic className="h-5 w-5" />}
          {isRecording ? t.stopRecording : t.startRecording}
        </button>
        
        <button
          onClick={() => fileInputRef.current?.click()}
          className="flex items-center justify-center gap-2 px-4 py-3 bg-gray-100 text-gray-700 rounded-lg hover:bg-gray-200 transition-colors"
        >
          <Upload className="h-5 w-5" />
          {t.uploadFile}
        </button>
        
        <input
          ref={fileInputRef}
          type="file"
          accept="audio/*"
          onChange={handleFileUpload}
          className="hidden"
        />
      </div>
      
      {error && (
        <div className="mb-4 p-3 bg-red-50 border border-red-200 rounded-lg">
          <p className="text-red-700 text-sm">{error}</p>
        </div>
      )}
      
      {/* Audio Files List */}
      <div className="space-y-3">
        {audioFiles.length === 0 ? (
          <div className="text-center py-8 text-gray-500">
            <FileAudio className="h-12 w-12 mx-auto mb-3 opacity-50" />
            <p className="text-sm">{t.noFiles}</p>
          </div>
        ) : (
          audioFiles.map(audioFile => (
            <div
              key={audioFile.id}
              className="border border-gray-200 rounded-lg p-4 hover:border-gray-300 transition-colors"
            >
              <div className="flex items-center justify-between mb-3">
                <div className="flex items-center gap-3">
                  <FileAudio className="h-5 w-5 text-blue-500" />
                  <div>
                    <p className="font-medium text-gray-900">{audioFile.name}</p>
                    {audioFile.duration > 0 && (
                      <p className="text-sm text-gray-500">
                        {t.duration}: {formatDuration(audioFile.duration)}
                      </p>
                    )}
                  </div>
                </div>
                
                <div className="flex items-center gap-2">
                  <button
                    onClick={() => playAudio(audioFile)}
                    className="p-2 text-gray-600 hover:text-blue-600 transition-colors"
                  >
                    {playingId === audioFile.id ? (
                      <Pause className="h-4 w-4" />
                    ) : (
                      <Play className="h-4 w-4" />
                    )}
                  </button>
                  
                  {!audioFile.transcription && !audioFile.isProcessing && (
                    <button
                      onClick={() => processTranscription(audioFile)}
                      className="px-3 py-1 bg-blue-100 text-blue-700 rounded text-sm hover:bg-blue-200 transition-colors"
                    >
                      {t.transcribe}
                    </button>
                  )}
                  
                  <button
                    onClick={() => deleteAudioFile(audioFile.id)}
                    className="p-2 text-gray-600 hover:text-red-600 transition-colors"
                  >
                    <Trash2 className="h-4 w-4" />
                  </button>
                </div>
              </div>
              
              {audioFile.isProcessing && (
                <div className="flex items-center gap-2 text-blue-600 text-sm">
                  <div className="animate-spin rounded-full h-4 w-4 border-2 border-blue-600 border-t-transparent" />
                  {t.processing}
                </div>
              )}
              
              {audioFile.transcription && (
                <div className="mt-3 p-3 bg-green-50 border border-green-200 rounded-lg">
                  <p className="text-sm text-green-800 mb-1 font-medium">{t.transcriptionComplete}</p>
                  <p className="text-sm text-gray-700">{audioFile.transcription}</p>
                </div>
              )}
            </div>
          ))
        )}
      </div>
    </div>
  );
};

export default VoiceInputProcessor;