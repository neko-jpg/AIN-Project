# app/main.py (Enhanced with custom prompt execution)

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import google.generativeai as genai
import json
import logging
from fastapi.middleware.cors import CORSMiddleware
import datetime
from typing import Dict, Any, List, Optional

# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
load_dotenv()

# --- FastAPIã‚¢ãƒ—ãƒªã¨CORSã®è¨­å®š ---
app = FastAPI(
    title="AI Navigator (AIN) Backend",
    description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦ä»¶ã«åŸºã¥ã„ã¦æœ€é©ãªAIæ§‹æˆã¨ã€å¯¾è©±çš„ã«ä¿®æ­£å¯èƒ½ãªæœ¬æ ¼çš„ãªä¼ç”»æ›¸ã‚’ææ¡ˆã™ã‚‹APIã§ã™ã€‚",
    version="9.0.0"
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Gemini APIã®è¨­å®š ---
try:
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•° 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    genai.configure(api_key=api_key)
except Exception as e:
    logging.critical(f"Gemini APIã‚­ãƒ¼ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    raise RuntimeError("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã€‚")

# --- Pydanticãƒ¢ãƒ‡ãƒ« ---
class UserPayload(BaseModel):
    purpose: str
    project_type: str
    budget: int
    experience_level: str
    weekly_hours: str
    development_time: Optional[int] = None
    language: Optional[str] = "ja"

class RefinementRequest(BaseModel):
    user_payload: UserPayload
    current_proposal: str
    refinement_request: str

class RefinementResponse(BaseModel):
    type: str
    content: str

class CustomPromptRequest(BaseModel):
    prompt: str
    language: Optional[str] = "en"

# --- çŸ¥è­˜ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ ---
KNOWLEDGE_BASE_STR = ""
try:
    all_knowledge_data = []
    directory_path = "data"
    if os.path.isdir(directory_path):
        json_files = sorted([f for f in os.listdir(directory_path) if f.endswith('.json')])
        for filename in json_files:
            file_path = os.path.join(directory_path, filename)
            with open(file_path, 'r', encoding='utf-8') as f:
                all_knowledge_data.extend(json.load(f))
    KNOWLEDGE_BASE_STR = json.dumps(all_knowledge_data, ensure_ascii=False)
    logging.info(f"åˆè¨ˆ {len(all_knowledge_data)} ä»¶ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ãƒˆãƒªã‚’èµ·å‹•æ™‚ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
except Exception as e:
    logging.error(f"èµ·å‹•æ™‚ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿å‡¦ç†å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼: {e}")

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆé–¢æ•° ---

def generate_initial_prompt(user_input: UserPayload) -> str:
    language_instruction = "Please respond in English." if user_input.language == "en" else "æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    
    return f"""
# å½¹å‰²: ã‚ãªãŸã¯ã€ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦ä»¶ã‹ã‚‰æœ€é©ãªæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚
# çŸ¥è­˜ãƒ™ãƒ¼ã‚¹: ```json
{KNOWLEDGE_BASE_STR}
```
# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦ä»¶:
- **ç›®çš„**: {user_input.purpose}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¨®é¡**: {user_input.project_type}
- **æœˆé¡äºˆç®—**: {user_input.budget}å†† ä»¥ä¸‹
- **é–‹ç™ºçµŒé¨“**: {user_input.experience_level}
- **é€±ã®é–‹ç™ºæ™‚é–“**: {user_input.weekly_hours}
- **é–‹ç™ºæœŸé–“**: {user_input.development_time or 6}ãƒ¶æœˆ
- **è¨€èªè¨­å®š**: {user_input.language}

{language_instruction}

# æŒ‡ç¤º: ä¸Šè¨˜ã«åŸºã¥ãã€æœ€é©ãªæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ§‹æˆæ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚AIãƒ¢ãƒ‡ãƒ«ã ã‘ã§ãªãã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€DBç­‰ã®AIä»¥å¤–ã®ãƒ„ãƒ¼ãƒ«ã‚‚ç¶²ç¾…çš„ã«è€ƒæ…®ã—ã€ãªãœãã‚Œã‚’é¸ã‚“ã ã®ã‹ç†ç”±ã‚’æ˜ç¢ºã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

# ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (Markdown)
---
### **ã”ææ¡ˆã™ã‚‹æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**
**1. æ§‹æˆæ¦‚è¦ã¨é¸å®šæ€æƒ³**
**2. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**
- **æ¨å¥¨ãƒ„ãƒ¼ãƒ«**:
- **é¸å®šç†ç”±**:
**3. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰**
- **æ¨å¥¨ãƒ„ãƒ¼ãƒ«**:
- **é¸å®šç†ç”±**:
**4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**
- **æ¨å¥¨ãƒ„ãƒ¼ãƒ«**:
- **é¸å®šç†ç”±**:
**5. ä¸»è¦ãªAIãƒ¢ãƒ‡ãƒ« / API**
- **æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**:
- **é¸å®šç†ç”±**:
**6. CI/CDã¨ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°**
- **æ¨å¥¨ãƒ„ãƒ¼ãƒ«**:
- **é¸å®šç†ç”±**:
"""

def generate_full_proposal_prompt(request: UserPayload) -> str:
    language_instruction = "Please respond in English." if request.language == "en" else "æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    
    return f"""
# å½¹å‰²: ã‚ãªãŸã¯ã€çµŒé¨“è±Šå¯Œãªã‚·ãƒ‹ã‚¢ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å…¼AIã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦ä»¶:
- ç›®çš„: {request.purpose}
- äºˆç®—: {request.budget}å††/æœˆ ä»¥ä¸‹
- çµŒé¨“: {request.experience_level}
- æ™‚é–“: {request.weekly_hours}/é€±
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¨®é¡: {request.project_type}
- é–‹ç™ºæœŸé–“: {request.development_time or 6}ãƒ¶æœˆ
- è¨€èªè¨­å®š: {request.language}

{language_instruction}

# çŸ¥è­˜ãƒ™ãƒ¼ã‚¹: ```json
{KNOWLEDGE_BASE_STR}
```
# æŒ‡ç¤º:
ä¸Šè¨˜æƒ…å ±ã‚’åŸºã«ã€æŠ•è³‡å®¶ã‚„çµŒå–¶å±¤ã«ã‚‚æå‡ºã§ãã‚‹ã€æœ€é«˜å“è³ªã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨é …ç›®ã‚’**ã™ã¹ã¦**å«ã‚ã€å…·ä½“çš„ã‹ã¤è«–ç†çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ã€Œ6. é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã€ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡ã«è¡Œã†ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ˜ç¢ºã«ç†è§£ã§ãã‚‹ã‚ˆã†ã€æ¥µã‚ã¦è©³ç´°ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

# ä¼ç”»æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (Markdown)
---
### **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåæ¡ˆ**
- æ¡ˆ1: (ã‚­ãƒ£ãƒƒãƒãƒ¼ã§è¦šãˆã‚„ã™ã„åå‰)
- æ¡ˆ2: (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…å®¹ã‚’çš„ç¢ºã«è¡¨ã™åå‰)
- æ¡ˆ3: (å…ˆé€²æ€§ã‚’æ„Ÿã˜ã•ã›ã‚‹åå‰)
### **1. ç›®çš„ã¨èƒŒæ™¯**
### **2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨èª²é¡Œ**
### **3. ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦**
### **4. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**
### **5. é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¨æœŸé–“**
### **6. é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ**
(ã€æœ€é‡è¦ã€‘ã€Œãƒ•ã‚§ãƒ¼ã‚º1: ç’°å¢ƒæ§‹ç¯‰ã€ã€Œãƒ•ã‚§ãƒ¼ã‚º2: ã‚³ã‚¢æ©Ÿèƒ½å®Ÿè£…ã€ã€Œãƒ•ã‚§ãƒ¼ã‚º3: UI/UXæ”¹å–„ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ã€ã®ã‚ˆã†ã«ãƒ•ã‚§ãƒ¼ã‚ºåˆ†ã‘ã—ã€å„ã‚¿ã‚¹ã‚¯ã«[æœŸé–“ç›®å®‰][ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«][é–¢é€£ãƒ„ãƒ¼ãƒ«]ã‚’ä»˜è¨˜ã—ã€ã€Œ**ğŸ’¡ã“ã®ã‚¿ã‚¹ã‚¯ã§è¡Œãè©°ã¾ã£ãŸã‚‰ã€AINã«ã€[ã‚¿ã‚¹ã‚¯å]ã«ã¤ã„ã¦ã‚‚ã£ã¨è©³ã—ãæ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¦ãã ã•ã„ã€‚**ã€ã¨ã„ã†æ¬¡ã®å¯¾è©±ã¸ã®èª˜å°ã‚’å¿…ãšå«ã‚ã‚‹ã“ã¨)
### **7. é–‹ç™ºä½“åˆ¶**
### **8. ãƒªã‚¹ã‚¯åˆ†æã¨å¯¾ç­–**
### **9. è²»ç”¨æ¦‚ç®—ã¨ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰äºˆæ¸¬**
### **10. ç«¶åˆåˆ†æã¨å·®åˆ¥åŒ–**
### **11. é¡ä¼¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆäº‹ä¾‹**
### **12. æœ€æ–°AIãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ**
### **13. æˆåŠŸæŒ‡æ¨™ (KPI)**
### **14. ä»Šå¾Œã®å±•æœ›**
### **15. 3æ®µéšã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¡ˆ**
- **æœ€å°æ§‹æˆ (MVP)**:
- **æ¨™æº–æ§‹æˆ**:
- **ç†æƒ³æ§‹æˆ**:
"""

def generate_refine_prompt(request: RefinementRequest) -> str:
    language_instruction = "Please respond in English." if request.user_payload.language == "en" else "æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    
    return f"""
# å½¹å‰²:
ã‚ãªãŸã¯ã€ŒAIã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã€ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æŒ‡ç¤ºã‚’åˆ†æã—ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{language_instruction}

# ãƒ«ãƒ¼ãƒ«:
1.  ã¾ãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºãŒã€Œç¾åœ¨ã®ä¼ç”»æ›¸ã€ã«ç›´æ¥é–¢é€£ã™ã‚‹ã€Œä¿®æ­£ä¾é ¼ã€ã‹ã€Œè³ªå•ã€ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
2.  **ä¿®æ­£ä¾é ¼ã®å ´åˆ**: ä¼ç”»æ›¸ã‚’æŒ‡ç¤ºé€šã‚Šã«ä¿®æ­£ã—ã€ä¿®æ­£å¾Œã®ä¼ç”»æ›¸å…¨ä½“ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å¿œç­”ã‚¿ã‚¤ãƒ—ã¯ "proposal" ã¨ã—ã¾ã™ã€‚
3.  **è³ªå•ã®å ´åˆ**: ä¼ç”»æ›¸ã¯å¤‰æ›´ã›ãšã€ãã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã®ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å¿œç­”ã‚¿ã‚¤ãƒ—ã¯ "answer" ã¨ã—ã¾ã™ã€‚
4.  **ä¼ç”»æ›¸ã«é–¢ä¿‚ãªã„å ´åˆ**: ã€Œç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ãã®ã”è³ªå•ã«ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚ä¼ç”»æ›¸ã«é–¢ã™ã‚‹å†…å®¹ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚ã€ã¨ã„ã†å›ºå®šã®æ–‡ç« ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å¿œç­”ã‚¿ã‚¤ãƒ—ã¯ "rejection" ã¨ã—ã¾ã™ã€‚
5.  ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¾Œã«ã€`(AINã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼š...Proãƒ—ãƒ©ãƒ³ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚)` ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯**å«ã‚ãªã„ã§ãã ã•ã„**ã€‚

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (JSON):
å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
{{
  "type": "proposal" | "answer" | "rejection",
  "content": "ã“ã“ã«ç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¼ç”»æ›¸å…¨ä½“ã€å›ç­”ã€ã¾ãŸã¯æ‹’å¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã‚’å…¥ã‚Œã‚‹"
}}

---
# å…¥åŠ›æƒ…å ±

## ç¾åœ¨ã®ä¼ç”»æ›¸:
```markdown
{request.current_proposal}
```

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆæœŸè¦ä»¶:
```json
{json.dumps(request.user_payload.model_dump(), ensure_ascii=False)}
```

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ä»Šå›ã®æŒ‡ç¤º:
ã€Œ{request.refinement_request}ã€

---
# ã‚ãªãŸã®å¿œç­” (JSONå½¢å¼ã§):
"""

# --- APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.post("/analyze_purpose/")
async def analyze_purpose(request: UserPayload):
    try:
        prompt = generate_initial_prompt(request)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = await model.generate_content_async(prompt)
        return {"suggestion": response.text}
    except Exception as e:
        logging.error(f"/analyze_purpose/ ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate_full_proposal/")
async def generate_full_proposal(request: UserPayload):
    try:
        prompt = generate_full_proposal_prompt(request)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = await model.generate_content_async(prompt)
        return {"suggestion": response.text}
    except Exception as e:
        logging.error(f"/generate_full_proposal/ ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/refine_proposal/", response_model=RefinementResponse)
async def refine_proposal_endpoint(request: RefinementRequest):
    try:
        prompt = generate_refine_prompt(request)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        
        generation_config = genai.types.GenerationConfig(
            response_mime_type="application/json"
        )
        
        response = await model.generate_content_async(prompt, generation_config=generation_config)
        
        response_json = json.loads(response.text)

        return RefinementResponse(
            type=response_json.get("type", "answer"),
            content=response_json.get("content", "ã‚¨ãƒ©ãƒ¼ï¼šå¿œç­”ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        )

    except Exception as e:
        logging.error(f"/refine_proposal/ ã‚¨ãƒ©ãƒ¼: {e}")
        return RefinementResponse(
            type="answer",
            content=f"å¤§å¤‰ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚({e})"
        )

@app.post("/execute_custom_prompt/")
async def execute_custom_prompt(request: CustomPromptRequest):
    try:
        language_instruction = "Please respond in English." if request.language == "en" else "æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        
        enhanced_prompt = f"""
{language_instruction}

# Knowledge Base: ```json
{KNOWLEDGE_BASE_STR}
```

# User's Custom Prompt:
{request.prompt}

Please provide a comprehensive and helpful response based on the user's request and the available knowledge base.
"""
        
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = await model.generate_content_async(enhanced_prompt)
        return {"suggestion": response.text}
    except Exception as e:
        logging.error(f"/execute_custom_prompt/ ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
def read_root():
    return {"message": "AI Navigator (AIN) Backend v9.0 is running with enhanced features."}